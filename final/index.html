<html>

<head>
	<title>Infovis2020 Final Task</title>
	<script src="lib/three.min.js"></script>
	<script src="lib/TrackballControls.js"></script>
	<script src="lib/Lut.js"></script>
	<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/110/three.min.js"></script> -->
	<!-- <script src="https://threejs.org/examples/js/controls/TrackballControls.js"></script> -->
	<script src="https://naohisas.github.io/KVS.js/Build/KVS.min.js"></script>
	<script src="https://naohisas.github.io/KVS.js/Build/KVS2THREE.min.js"></script>
	<!-- <script src="lib/KVS2THREE.js"></script> -->
	<script src="https://naohisas.github.io/KVS.js/Source/KVSLobsterData.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/dat-gui/0.7.7/dat.gui.min.js"></script>
	<script src="lib/color.js"></script>

	<script type="x-shader/x-vertex" id="bounding.vert">
	 varying vec4 position_obj;

	 void main()
	 {
	     gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );

	     position_obj = vec4( position, 1.0 );
	 }
	</script>

	<script type="x-shader/x-fragment" id="bounding.frag">
	 varying vec4 position_obj;

	 void main()
	 {
	     gl_FragColor = position_obj;
	 }
	</script>

	<script type="x-shader/x-vertex" id="raycaster.vert">
	 varying vec4 position_obj;
	 varying vec4 position_clp;

	 void main()
	 {
	     gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );

	     position_obj = vec4( position, 1.0 );
	     position_clp = gl_Position;
	 }
	</script>

	<script type="x-shader/x-fragment" id="raycaster.frag">
	varying vec4 position_obj;
	varying vec4 position_clp;
	uniform vec3 volume_resolution;
	uniform sampler2D exit_points;
	uniform sampler2D volume_data;
	uniform sampler2D transfer_function_data;
	uniform vec3 light_position;
	uniform vec3 camera_position;
	uniform vec3 background_color;
	uniform float first_hit_threshold;
	uniform bool blinn_phong_reflection_enable;
	uniform float dt;
	// 0: default(accumulate), 1: x-ray 2: mip 3: first hit
	uniform int mode;
	uniform bool linear_interpolation;

	vec4 LookupTexture2D( sampler2D texture, vec2 index ) {
		return texture2D( texture, index );
	}

	vec4 LookupTexture3D( sampler2D texture, vec3 resolution, vec3 index ) {
		index.x = clamp( index.x, 0.0, 1.0 );
		vec3 p = index * ( resolution - vec3( 1.0 ) );

		float z = min( p.z, resolution.z - 1.0 );
		float z0 = min( floor( p.z ), resolution.z - 1.0 );
		float z1 = min( z0 + 1.0, resolution.z - 1.0 );

		float u0 = resolution.x * z0 + p.x;
		float u1 = resolution.x * z1 + p.x;
		float v = p.y;

		float width = resolution.x * resolution.z;
		float height = resolution.y;

		vec4 s0 = LookupTexture2D( texture, vec2( u0 / ( width - 1.0 ), v / ( height - 1.0 ) ) );
		vec4 s1 = LookupTexture2D( texture, vec2( u1 / ( width - 1.0 ), v / ( height - 1.0 ) ) );
		return mix( s0, s1, z - z0 );
	}

	vec3 VolumeGradient( sampler2D v, vec3 r, vec3 p, vec3 o ) {
		float s0 = LookupTexture3D( v, r, p + vec3( o.x, 0.0, 0.0 ) ).w;
		float s1 = LookupTexture3D( v, r, p + vec3( 0.0, o.y, 0.0 ) ).w;
		float s2 = LookupTexture3D( v, r, p + vec3( 0.0, 0.0, o.z ) ).w;
		float s3 = LookupTexture3D( v, r, p - vec3( o.x, 0.0, 0.0 ) ).w;
		float s4 = LookupTexture3D( v, r, p - vec3( 0.0, o.y, 0.0 ) ).w;
		float s5 = LookupTexture3D( v, r, p - vec3( 0.0, 0.0, o.z ) ).w;
		return vec3( s3 - s0, s4 - s1, s5 - s2 );
	}

	vec3 BlinnPhongReflection( vec3 C, vec3 L, vec3 N, vec3 V ) {
		float ka = 0.3;
		float kd = 0.5;
		float ks = 0.8;
		float n = 50.0;

		vec3 H = normalize( L + V );
		float dd = max( dot( N, L ), 0.0 );
		float ds = 0.0;
		if ( dd > 0.0 ) {
			ds = pow( max( dot( H, N ), 0.0 ), n );
		}

		float Ia = ka;
		float Id = kd * dd;
		float Is = ks * ds;
		return C * ( Ia + Id + Is );
	}

	void main() {
		float x = ( position_clp.x / position_clp.w + 1.0 ) / 2.0;
		float y = ( position_clp.y / position_clp.w + 1.0 ) / 2.0;
		vec2 index = vec2( x, y );
		vec3 exit_point = texture2D( exit_points, index ).xyz;
		vec3 entry_point = position_obj.xyz;
		if ( entry_point == exit_point ) { discard; return; }

		float segment = distance( exit_point, entry_point );
		vec3 direction = dt * normalize( exit_point - entry_point );

		int nsteps = int( floor( segment / dt ) );
		if ( nsteps == 0 ) nsteps++;

		float opaque = 0.95;
		vec3 position = entry_point;
		vec4 color = vec4( 0.0, 0.0, 0.0, 0.0 );

		if(mode == 0) {
			// accumulate
			for ( int i = 0; i < 10000; i++ ) {
				vec3 volume_index = vec3( ( position + vec3( 0.5 ) ) / volume_resolution );

				float s = LookupTexture3D( volume_data, volume_resolution, volume_index ).a;
				vec4 c = LookupTexture2D( transfer_function_data, vec2( s, 0.0 ) );

				if ( c.a != 0.0 ) {
					if(blinn_phong_reflection_enable) {
						vec3 offset_index = vec3( 1.0 ) / volume_resolution;
						vec3 normal = VolumeGradient( volume_data, volume_resolution, volume_index, offset_index );
	
						vec3 L = normalize( light_position - position );
						vec3 N = normalize( normal );
						vec3 V = normalize( camera_position - position );
						c.rgb = BlinnPhongReflection( c.rgb, L, N, V );
					}

					// Front-to-back composition.
					color.rgb += ( 1.0 - color.a ) * c.a * c.rgb;
					color.a += ( 1.0 - color.a ) * c.a;

					// Early ray termination.
					if ( color.a > opaque ) {
						color.a = 1.0;
						break;
					}
				}

				position += direction;

				if ( i > nsteps ) { break; }
			}
		}
		else if(mode == 1) {
			// x-ray
			vec4 c_sum = vec4( 0.0, 0.0, 0.0, 0.0);
			int c_count = 0;
			
			for ( int i = 0; i < 10000; i++ ) {
				vec3 volume_index = vec3( ( position + vec3( 0.5 ) ) / volume_resolution );

				float s = LookupTexture3D( volume_data, volume_resolution, volume_index ).a;
				vec4 c = LookupTexture2D( transfer_function_data, vec2( s, 0.0 ) );

				if ( c.a != 0.0 ) {
					vec3 offset_index = vec3( 1.0 ) / volume_resolution;
					vec3 normal = VolumeGradient( volume_data, volume_resolution, volume_index, offset_index );

					if(blinn_phong_reflection_enable) {
						vec3 L = normalize( light_position - position );
						vec3 N = normalize( normal );
						vec3 V = normalize( camera_position - position );
						c.rgb = BlinnPhongReflection( c.rgb, L, N, V );
					}
					c_sum += c;
					c_count++;
				}

				position += direction;

				if ( i > nsteps ) { break; }
			}

			// get average color
			vec4 c = c_count > 0 ? c_sum / float(c_count) : vec4(0.0, 0.0, 0.0, 0.0);
			if(c.a != 0.0){
				color.rgb = c.rgb;
				color.a = c.a;
			}
		}
		else if(mode == 2) {
			// maximum intensity projection
			float a_max = 0.0;
			vec3 pos_max = vec3( 0.0, 0.0, 0.0);
			for ( int i = 0; i < 10000; i++ ) {
				vec3 volume_index = vec3( ( position + vec3( 0.5 ) ) / volume_resolution );

				float s = LookupTexture3D( volume_data, volume_resolution, volume_index ).a;
				vec4 c = LookupTexture2D( transfer_function_data, vec2( s, 0.0 ) );

				if(c.a > a_max) {
					a_max = c.a;
					pos_max = position;
				}

				position += direction;

				if ( i > nsteps ) { break; }
			}


			if ( a_max != 0.0 ) {
				vec3 volume_index = vec3( ( pos_max + vec3( 0.5 ) ) / volume_resolution );

				float s = LookupTexture3D( volume_data, volume_resolution, volume_index ).a;
				vec4 c = LookupTexture2D( transfer_function_data, vec2( s, 0.0 ) );

				if(blinn_phong_reflection_enable) {
					vec3 offset_index = vec3( 1.0 ) / volume_resolution;
					vec3 normal = VolumeGradient( volume_data, volume_resolution, volume_index, offset_index );
	
					vec3 L = normalize( light_position - pos_max );
					vec3 N = normalize( normal );
					vec3 V = normalize( camera_position - pos_max );
					c.rgb = BlinnPhongReflection( c.rgb, L, N, V );
				}

				color.rgb = c.rgb;
				color.a = c.a;
			}
		}
		else if(mode == 3){
			// first hit
			vec4 c_prev = vec4( 0.0, 0.0, 0.0, 0.0 );
			for ( int i = 0; i < 10000; i++ ) {
				vec3 volume_index = vec3( ( position + vec3( 0.5 ) ) / volume_resolution );

				float s = LookupTexture3D( volume_data, volume_resolution, volume_index ).a;
				vec4 c = LookupTexture2D( transfer_function_data, vec2( s, 0.0 ) );

				if ( c.a != 0.0 ) {
					if(blinn_phong_reflection_enable) {
						vec3 offset_index = vec3( 1.0 ) / volume_resolution;
						vec3 normal = VolumeGradient( volume_data, volume_resolution, volume_index, offset_index );
	
						vec3 L = normalize( light_position - position );
						vec3 N = normalize( normal );
						vec3 V = normalize( camera_position - position );
						c.rgb = BlinnPhongReflection( c.rgb, L, N, V );
					}
					if(c.a > first_hit_threshold){
						if(linear_interpolation){
							float k = (first_hit_threshold - c_prev.a)/(c.a - c_prev.a);
							c.rgb = k * c.rgb + (1.0 - k) * c_prev.rgb;
							c.a = k * c.a + (1.0-k) * c_prev.a;
						}

						color.rgb = c.rgb;
						color.a = c.a;
						break;
					}
				}

				position += direction;
				c_prev = c;

				if ( i > nsteps ) { break; }
			}
		}

		color.rgb += ( 1.0 - color.a ) * background_color;

		gl_FragColor = color;
	}
	</script>

	<script src="src/colormap.js"></script>
	<script src="src/main.js"></script>
</head>

<body style="margin:8px">
	<script>
		main();
	</script>

	<h1>Information Visualization 2020 Final Task (T2: Algorithm Implementation)</h1>
	<h2>Overview</h2>
	<p>I implemented the follwing features.</p>
	<ul>
		<li>
			Colormap
			<ul>
				<li>
					Diverging Colormap Generation
				</li>
			</ul>
		</li>
		<li>
			Volume Rendering
			<ul>
				<li>
					X-Ray/MIP
				</li>
				<li>
					First Hit(Raycast-based isosurface extraction)
					<ul>
						<li>
							linear interpolation
						</li>
					</ul>
				</li>
			</ul>
		</li>
	</ul>

	<h2>Controlls</h2>
	<p>
		The interface avobe the webpage is implemented by <a href="https://github.com/dataarts/dat.gui">dat.gui</a>.
		It contains some controlls around Colormap and Volume Rendering.
		In addition, we can toggle Blinn Phong Reflection shading (enable in default).
	</p>

	<h2>Colormap</h2>
	<p>
		I implemented Diverging Colormap Generation algorithm, that is described in
		<a href="https://www.kennethmoreland.com/color-maps/">https://www.kennethmoreland.com/color-maps/</a> and
		<a href="https://www.kennethmoreland.com/color-maps/ColorMapsExpanded.pdf">
			https://www.kennethmoreland.com/color-maps/ColorMapsExpanded.pdf</a>.
	</p>
	<p>
		First, We have to convert a RGB color to Msh color, via CIE Lab color space.
		I wrote the conversion function between Msh and CIE Lab, but I used
		<a href="https://github.com/antimatter15/rgb-lab">rgb-lab</a> library to convert between RGB and CIE Lab.
	</p>
	<p>
		Next, the interpolation function in Msh color space is needed.
		The full paper shows pseudo program code, so I translated it into JavaScript.
	</p>
	<p>
		The controll provides 4 colormap options.
		Two of them are the diverging colormap, descripted in the original paper.
		For compalision, I added a RGB-based linear colormap (white to red) and a rainbow colormap.
	</p>
	<p>
		In addition, I integrated the <a href="https://threejs.org/examples/webgl_geometry_colors_lookuptable">Lut</a>
		colormap legend into the GUI interface, so that the in-3D-view colormap can be updated dinamically, according to
		the selection in the controll.
	</p>

	<h2>Volume Rendering</h2>
	<p>
		Volume Rendering splits the volumes in the way of raycasting.
		The controll GUI has a option to change sampling rate.
		So we can confirm that the fine sampling (small value) makes the look better instead of the increasing of
		computation cost.
	</p>

	<p>
		There is a controll to change volume rendering mode.
		In addition to the default accumulate mode, we can switch to X-ray, MIP, and first-hit (raycast based
		isosurface) modes.
	</p>

	<h3>X-ray/MIP</h3>
	<p>
		Both X-ray and MIP checks all the position in the way of ray.
	</p>
	<p>
		In X-ray mode, the program sums all non-zero value in the path and finally divides the sum by the number of
		non-zero values.
		It looks like X-ray literally, we see through backward volumes.
	</p>
	<p>
		In MIP mode, check all value and simply use the maximum value.
		Like X-ray we can see through the inside of the object, but MIP shows the internal structure of the object more
		clearly.
	</p>

	<h3>raycast based isosurface extraction</h3>
	<p>
		Lastly, I implemented first-hit (raycast based isosurface) volume rendering.
		The first-hit volume rendering checks the value in the path, and pick the first value that is larger than a specific threshold value.
		It realizes raycast-based isosurface extraction.
	</p>
	<p>
		The controll has 2 more options dedicated to this mode.
	</p>
	<p>
		The "first hit threshold" option enables to change the first-hit threshold.
		By changing this value, we see various isosurfaces.
	</p>
	<p>
		And I implemented a linear interpolation, to improve the first-hit algorithm.
		In simple implementation of first-hit algorithm, striped pattern appears everywhere, especially when the sampling rate is not fine enough.
		The improved program remembers the previous value in the path, and interpolate linearly between the two point around the threshold.
		This algorithm significantly makes the model smooth, especially when the sampling rate is large.
		We can check the effect of the interpolation to set large sampling rate (.75 or more) and toggle the interpolation checkbox.
	</p>
	
	<h2>Result</h2>
	<p>
		I implemented algorithms around colormap and volume rendering.
		And I integrated the UI so that we can confirm the effect of those algorithms.
	</p>

	<p>
		If the program in this webpage does not work correctly, please use the latest version of Google Chrome.
	</p>

	<hr>
	<p><a href="https://github.com/Tatamo/infovis2020">GitHub repository</a></p>
	<p><a href="../">index</a></p>
</body>

</html>
